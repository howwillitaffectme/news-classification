{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1988764-6826-495f-b6be-ee321951154b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Text classification for fake news detection\n",
    "\n",
    "In this notebook I train and evaluate 3 different ML models from sklearn library, namely:\n",
    "- Passive Aggressive Classifier\n",
    "- Logistic Regression\n",
    "- Linear SVC\n",
    "\n",
    "All three models use TF-iDF vectorizer, a frequency based textvectorizer.\n",
    "The models will classify news based only on the text or title of the news.\n",
    "\n",
    "The investigation is structured in the following manner:\n",
    "1. Read and preprocess data.\n",
    "2. Split data into training and test sets, vectorize it for models input.\n",
    "3. Training and evaluation of models.\n",
    "4. Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaaf646-485a-474f-bfdc-9749cb598d1a",
   "metadata": {},
   "source": [
    "Download dataset: https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset and extract into the same folder this notebook is in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d1f0b1f-53be-4ee9-b273-8dea60e44cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "# text processing, term frequency based\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "# models\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier, LogisticRegression\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be85617a-25e5-430a-a808-34d03d530a41",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "The input data is not 'clean'. Apperently many \"true\" news contain a source in the begining of their \"text\" field, and many \"fake\" news contain related pic info in the end of their \"text\" field, this can cause bias for a model, so we can cut them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59522b62-1bb8-41ae-a841-5fdb23237ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutsource(s):\n",
    "    ''' a function to cut out news source in \"true\" texts\n",
    "        luckily they are separated by '-' (dash sign)\n",
    "    '''\n",
    "    if '- ' in s:\n",
    "        s1 = s.split('- ')[0]\n",
    "        s = s[len(s1)+2:]\n",
    "        \n",
    "    return s\n",
    "\n",
    "def cutgetty(s):\n",
    "    ''' a function to cut out 'getty images' in \"fake\" texts\n",
    "    '''\n",
    "    s = re.sub('Getty Images', '', s)\n",
    "    \n",
    "    return s\n",
    "\n",
    "def cutfactbox(s):\n",
    "    ''' a function to cut out 'factbox' in \"true\" titles\n",
    "    '''\n",
    "    s = re.sub('factbox', '', s, flags=re.IGNORECASE)\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55981c0b-97fe-42e5-84f1-0bad6c12ef3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = pd.read_csv('Fake.csv')\n",
    "true = pd.read_csv('True.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03180ebf-19cb-49c9-9686-0ba7f7ac0f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaked Email Proves Trump Officials Aware Russia Had ‘Thrown The USA Election’ To Trump\n",
      "Donald Trump s current deputy national security adviser K.T. McFarland, a former Fox News personality, K. T. McFarland admitted in an email to a colleague during the 2016 presidential transition to Russia throwing the election to Trump. The leaked email was written just weeks before Trump s inauguration and it states that sanctions would make it difficult to ease relations with Russia,  which has just thrown the U.S.A. election to him. The New York Times reports:But emails among top transition officials, provided or described to The New York Times, suggest that Mr. Flynn was far from a rogue actor. In fact, the emails, coupled with interviews and court documents filed on Friday, showed that Mr. Flynn was in close touch with other senior members of the Trump transition team both before and after he spoke with the Russian ambassador, Sergey I. Kislyak, about American sanctions against Russia.A White House lawyer tried to explain McFarland s email to the The Times by saying that she was referring to the Democrats  portrayal of the election. That doesn t make any sense, by the way.McFarland wrote the email to Thomas P. Bossert, who currently serves as Trump s homeland security adviser, then he forwarded it to future National Security Advisor Michael Flynn (now indicted), future Chief of Staff Reince Priebus, future senior strategist Stephen Bannon, and future press secretary Sean Spicer, the Daily Beast reports.With all the pearl-clutching we witnessed from conservatives about Hillary Clinton s emails, you d think they wouldn t be sending messages about Russia throwing the election to Trump.This past March, John Oliver, the host of the HBO comedy show Last Week Tonight started a segment called  Stupid Watergate,  which he described as  a scandal with all the potential ramifications of Watergate, but where everyone involved is stupid and bad at everything. Nailed it!Photo by Chip Somodevilla/.\n",
      "fake\n"
     ]
    }
   ],
   "source": [
    "true['text'] = true['text'].apply(cutsource)\n",
    "fake['text'] = fake['text'].apply(cutgetty)\n",
    "true['title'] = true['title'].apply(cutfactbox)\n",
    "# combine data into 1 dataframe, discarding 'date' and 'subject' fields, \n",
    "# removing rows with empty text or title.\n",
    "cols = ['title', 'text']\n",
    "df = pd.concat([fake[cols], true[cols]], ignore_index=True)\n",
    "df['text'] = df['text'].str.strip()\n",
    "df['title'] = df['title'].str.strip()\n",
    "label = len(fake)*['fake'] + len(true)*['true']\n",
    "df['label'] = label\n",
    "# drop news shorter than a tweet\n",
    "df = df[df['text'].str.len() > 280]\n",
    "df = df.replace('', np.nan)\n",
    "df.dropna(inplace=True)\n",
    "df['label'].value_counts()\n",
    "example = df.iloc[42]\n",
    "print(example['title'] + '\\n' + example['text'] + '\\n' + example['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412d4020-76f5-4e0f-9a8e-889bf330bbd0",
   "metadata": {},
   "source": [
    "### Machine learning time. \n",
    "Training will consider 2 cases: title only and text only classification.\n",
    "\n",
    "For word processing I use TF-iDF, a frequency based metric, which checks the occurence of a term against a given text and the whole corpus.\n",
    "\n",
    "Here I construct a function for evaluation of different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cf59cc9-7063-4a1e-b9ce-c6e511fad000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(df_col):\n",
    "    '''split data into train and test, turn into vectors.\n",
    "    '''\n",
    "    x_train,x_test,y_train,y_test=train_test_split(df[df_col], df['label'], test_size=0.2, random_state=42, shuffle=True)\n",
    "    # Learn vocabulary and idf, return document-term matrix.\n",
    "    tfidf_vectorizer=TfidfVectorizer(stop_words='english', max_df=0.75)\n",
    "    vec_train=tfidf_vectorizer.fit_transform(x_train.values.astype('U')) \n",
    "    # Transform documents to document-term matrix.\n",
    "    vec_test=tfidf_vectorizer.transform(x_test.values.astype('U'))\n",
    "    \n",
    "    return (tfidf_vectorizer, vec_train, vec_test, y_train, y_test)\n",
    "    \n",
    "def model_eval(input_data, model):\n",
    "    '''function to report f1 scores for a model\n",
    "        based on classification based on df_col (text or title)\n",
    "        tdidf_vectorizer\n",
    "        https://github.com/satssehgal/FakeNewsDetector\n",
    "    '''\n",
    "    tfidf_vectorizer, vec_train, vec_test, y_train, y_test = input_data\n",
    "    model.fit(vec_train,y_train)\n",
    "    y_pred=model.predict(vec_test)\n",
    "    f1 = f1_score(y_test, y_pred, pos_label='fake')\n",
    "    # let's see what are the top terms for fake and true news (largest vectors)\n",
    "    # https://www.datacamp.com/community/tutorials/scikit-learn-fake-news\n",
    "    terms = tfidf_vectorizer.get_feature_names_out()\n",
    "    keywords = sorted(zip(model.coef_[0], terms), reverse=True)\n",
    "    keywords_true = np.array(keywords[:20])\n",
    "    keywords_fake = np.flip(np.array(keywords[-20:]), axis=0)\n",
    "    true_out = keywords_true[:, 1]\n",
    "    fake_out = keywords_fake[:, 1]\n",
    "\n",
    "    print('F1 score', f1)\n",
    "    print('\\t True keywords: \\n', true_out)\n",
    "    print('\\t Fake keywords: \\n', fake_out)\n",
    "    \n",
    "    return (f1, true_out, fake_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80fe08ea-be91-451e-b3ef-979f3a72c392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*--------- PassiveAggressiveClassifier ---------*\n",
      "## Title based classification ##\n",
      "F1 score 0.9397288367323687\n",
      "\t True keywords: \n",
      " ['says' 'exclusive' 'spokesman' 'faults' 'fame' 'german' 'kabul'\n",
      " 'rohingya' 'kremlin' 'pakistan' 'hindu' 'blitz' 'myanmar' 'talks' 'weigh'\n",
      " 'collar' 'employs' 'vulgar' 'fights' 'urges']\n",
      "\t Fake keywords: \n",
      " ['video' 'breaking' 'racist' 'gop' 'just' 'joe' 'hillary' 'james'\n",
      " 'illegals' 'anonymous' 'watch' 'actually' 'ck' 'gitmo' 'ammo' 'knees'\n",
      " 'dog' 'globalist' 'mails' 'dems']\n",
      "## Text based classification ##\n",
      "F1 score 0.9878857142857143\n",
      "\t True keywords: \n",
      " ['thursday' 'tuesday' 'wednesday' 'nov' 'friday' 'reuters' 'republican'\n",
      " 'monday' 'donald' 'rival' 'spokeswoman' 'comment' 'representatives'\n",
      " 'statement' 'referring' 'spokesman' 'reporters' 'barack' 'saying' 'edt']\n",
      "\t Fake keywords: \n",
      " ['featured' 'image' 'read' 'gop' 'com' 'sen' 'just' 'pic' 'watch' 'rep'\n",
      " 'breitbart' 'wfb' 'mr' 'https' 'daily' 'hillary' 'wire' 'mail'\n",
      " 'reportedly' '21st']\n",
      "*--------- LogisticRegression ---------*\n",
      "## Title based classification ##\n",
      "F1 score 0.9417195614541258\n",
      "\t True keywords: \n",
      " ['says' 'china' 'house' 'talks' 'myanmar' 'senate' 'urges' 'german'\n",
      " 'south' 'turkey' 'pm' 'britain' 'lawmakers' 'brexit' 'tax' 'eu' 'ex'\n",
      " 'probe' 'exclusive' 'opposition']\n",
      "\t Fake keywords: \n",
      " ['video' 'hillary' 'watch' 'breaking' 'just' 'gop' 'america' 'tweets'\n",
      " 'muslim' 'racist' 'donald' 'details' 'bernie' 'obama' 'boiler' 'isis'\n",
      " 'wow' 'black' 'images' 'liberal']\n",
      "## Text based classification ##\n",
      "F1 score 0.9764989109251404\n",
      "\t True keywords: \n",
      " ['wednesday' 'reuters' 'thursday' 'tuesday' 'republican' 'friday' 'monday'\n",
      " 'spokesman' 'statement' 'nov' 'presidential' 'reporters' 'minister'\n",
      " 'comment' 'democratic' 'told' 'representatives' 'spokeswoman' 'sunday'\n",
      " 'edt']\n",
      "\t Fake keywords: \n",
      " ['image' 'featured' 'just' 'read' 'gop' 'com' 'hillary' 'watch' 'america'\n",
      " 'pic' 'mr' 'like' 'https' 'sen' 'video' 'daily' 'rep' 'american' 'fact'\n",
      " 'wire']\n",
      "*--------- LinearSVC ---------*\n",
      "## Title based classification ##\n",
      "F1 score 0.9514119126557676\n",
      "\t True keywords: \n",
      " ['says' 'britain' 'german' 'urges' 'myanmar' 'rohingya' 'exclusive'\n",
      " 'spokesman' 'turkey' 'talks' 'singapore' 'pakistan' 'kremlin' 'house'\n",
      " 'faults' 'colombia' 'indonesian' 'spain' 'negotiations' 'egypt']\n",
      "\t Fake keywords: \n",
      " ['video' 'breaking' 'gop' 'just' 'hillary' 'watch' 'racist' 'bernie'\n",
      " 'boiler' 'illegals' 'isis' 'ck' 'actually' 'doj' 'dem' 'shocking' 'james'\n",
      " 'sharia' 'joe' 'anonymous']\n",
      "## Text based classification ##\n",
      "F1 score 0.9880013712718547\n",
      "\t True keywords: \n",
      " ['thursday' 'wednesday' 'tuesday' 'reuters' 'nov' 'friday' 'monday'\n",
      " 'republican' 'statement' 'spokesman' 'comment' 'spokeswoman' 'reporters'\n",
      " 'representatives' 'barack' 'donald' 'rival' 'presidential' 'referring'\n",
      " 'sunday']\n",
      "\t Fake keywords: \n",
      " ['featured' 'image' 'read' 'gop' 'just' 'com' 'sen' 'watch' 'pic'\n",
      " 'breitbart' 'rep' 'mr' 'daily' 'hillary' 'wfb' 'https' 'wire'\n",
      " 'reportedly' 'mail' '21st']\n"
     ]
    }
   ],
   "source": [
    "# split data into training and test sets, vectorize.\n",
    "title_data = data_split('title')\n",
    "text_data = data_split('text')\n",
    "\n",
    "# setting models and computing scores\n",
    "pac = PassiveAggressiveClassifier()\n",
    "lr = LogisticRegression()\n",
    "lsvc = LinearSVC()\n",
    "table = []\n",
    "for model in (pac, lr, lsvc):\n",
    "    print('*--------- '+type(model).__name__+' ---------*')\n",
    "    print('## Title based classification ##')\n",
    "    f1, true_m, fake_m = model_eval(title_data, model)\n",
    "    print('## Text based classification ##') \n",
    "    f1txt, true_mtxt, fake_mtxt = model_eval(text_data, model)\n",
    "    table.append([f1, true_m[:5], fake_m[:5], f1txt, true_mtxt[:5], fake_mtxt[:5]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42f71193-986d-440e-8ab8-8d22763828f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 score (title)</th>\n",
       "      <th>Top true (title)</th>\n",
       "      <th>Top fake (title)</th>\n",
       "      <th>F1 score (text)</th>\n",
       "      <th>Top true (text)</th>\n",
       "      <th>Top fake (text)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PAC</th>\n",
       "      <td>0.939729</td>\n",
       "      <td>[says, exclusive, spokesman, faults, fame]</td>\n",
       "      <td>[video, breaking, racist, gop, just]</td>\n",
       "      <td>0.987886</td>\n",
       "      <td>[thursday, tuesday, wednesday, nov, friday]</td>\n",
       "      <td>[featured, image, read, gop, com]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>0.941720</td>\n",
       "      <td>[says, china, house, talks, myanmar]</td>\n",
       "      <td>[video, hillary, watch, breaking, just]</td>\n",
       "      <td>0.976499</td>\n",
       "      <td>[wednesday, reuters, thursday, tuesday, republ...</td>\n",
       "      <td>[image, featured, just, read, gop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinSVC</th>\n",
       "      <td>0.951412</td>\n",
       "      <td>[says, britain, german, urges, myanmar]</td>\n",
       "      <td>[video, breaking, gop, just, hillary]</td>\n",
       "      <td>0.988001</td>\n",
       "      <td>[thursday, wednesday, tuesday, reuters, nov]</td>\n",
       "      <td>[featured, image, read, gop, just]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        F1 score (title)                            Top true (title)  \\\n",
       "PAC             0.939729  [says, exclusive, spokesman, faults, fame]   \n",
       "LogReg          0.941720        [says, china, house, talks, myanmar]   \n",
       "LinSVC          0.951412     [says, britain, german, urges, myanmar]   \n",
       "\n",
       "                               Top fake (title)  F1 score (text)  \\\n",
       "PAC        [video, breaking, racist, gop, just]         0.987886   \n",
       "LogReg  [video, hillary, watch, breaking, just]         0.976499   \n",
       "LinSVC    [video, breaking, gop, just, hillary]         0.988001   \n",
       "\n",
       "                                          Top true (text)  \\\n",
       "PAC           [thursday, tuesday, wednesday, nov, friday]   \n",
       "LogReg  [wednesday, reuters, thursday, tuesday, republ...   \n",
       "LinSVC       [thursday, wednesday, tuesday, reuters, nov]   \n",
       "\n",
       "                           Top fake (text)  \n",
       "PAC      [featured, image, read, gop, com]  \n",
       "LogReg  [image, featured, just, read, gop]  \n",
       "LinSVC  [featured, image, read, gop, just]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_ev = pd.DataFrame(table, index=['PAC', 'LogReg', 'LinSVC'], \n",
    "                         columns=['F1 score (title)', 'Top true (title)', 'Top fake (title)', \n",
    "                                 'F1 score (text)', 'Top true (text)', 'Top fake (text)'])\n",
    "models_ev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e862df6-36ea-4010-9e4b-cf7447276feb",
   "metadata": {},
   "source": [
    "NOTE: because of shuffle of input data the keywords might differ from run to run (e.g. starting a new kernel), I think the seed for random_state in train_test_split() is not uniquely determined for a given number.\n",
    "\n",
    "### Summary\n",
    "From the textbased classification we can conclude that the models identified true news as the ones that refer to to a person or other news, like 'said', 'showed', 'citing', 'comment' as well as containing a date (day).\n",
    "On the other hand, fake news seem to refer to images a lot (presumably in the news article) or links on the internet (e.g. pic.twitter.com/*). Also in contrast true news refer to particular days, while fake news refer to rather time adverbs, like 'just', 'daily', 'reportedly'.\n",
    "Alternatively fake news refer to rather screenshots than text citations.\n",
    "\n",
    "It is also plausible that fake news appeal to visual comprehension of information in contrast to true news appealing to verbal/idea based information. \n",
    "\n",
    "The title based classification shows that keywords like \"shocking\", \"breaking\", \"racist\" were identified for fake news. Fake news are similar to a virus, they are aimed at getting as many clicks as possible in short amount of time, indeed the  keywords for fake news look like clickbaiting words. While true news seem to have more neutral and passive keywords. \n",
    "\n",
    "Within this investigation all models show similar high F1 scores, with PAC and LogReg being slightly better than LogReg most of the times. At the same time textbased modelling shows higher scores than titlebased, which is reasonable, the more information is available, the more precise one can be (to some extent).\n",
    "\n",
    "We can conclude that all the models showed reasonable results which we can also interpret in a clear understandable manner.\n",
    "\n",
    "PAC was my first choice since I didn't really know what to pick, then I took LogisiticRegression for it being the simplest and easiest to understand, and  SVC as google said is one of the best for text classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629eee31-ac67-4692-a137-116e2b5f8630",
   "metadata": {},
   "source": [
    "## CNN (Convolutional Neural Network) for text classification using PyTorch\n",
    "\n",
    "This part of investigation is an attempt to apply the CNN classification algorithm written for movie reviews [[2]](#references). \n",
    "\n",
    "I'll go through the following steps:\n",
    "1. Text preprocessing\n",
    "    - Embedding layer and Tokenization\n",
    "    - Padding\n",
    "2. CNN model\n",
    "3. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721f0fc1-ed75-40ce-bfc6-406e9f660bf2",
   "metadata": {},
   "source": [
    "### Text preprocessing\n",
    "\n",
    "I am going to use an embedding pre-trained layer to which I'd like to map words in the news. For that first I need to tokenize the news, i.e. turn them into lists of words, tokens and then map them to the embedding pre-trained layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dea97ec-8f00-4cae-9fb3-ff47ec5ddc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase the texts and remove punctuation\n",
    "df['text'] = df['text'].str.lower()\n",
    "df['text'] = df['text'].str.replace('[^\\w\\s]','', regex=True) # remove punctuation (everything that's not a word(also a number) or whitespace)\n",
    "texts_split = df['text'].str.split().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "930d4cd5-0e08-45bd-a598-151922807a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['donald',\n",
       " 'trump',\n",
       " 's',\n",
       " 'current',\n",
       " 'deputy',\n",
       " 'national',\n",
       " 'security',\n",
       " 'adviser',\n",
       " 'kt',\n",
       " 'mcfarland',\n",
       " 'a',\n",
       " 'former',\n",
       " 'fox',\n",
       " 'news',\n",
       " 'personality']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now the texts are lists of words\n",
    "texts_split[42][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ae67e8d-9021-489a-98a3-17a5155aeb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seems like I have 1 letter words which usually don't carry much semantic significance\n",
    "# let's get rid of them\n",
    "for i, text in enumerate(texts_split):\n",
    "    texts_split[i] = [word for word in text if len(word)>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d5bc1f6-b16d-4aba-9c38-c46e97c51b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['donald', 'trump', 'current', 'deputy', 'national', 'security', 'adviser', 'kt', 'mcfarland', 'former', 'fox', 'news', 'personality', 'mcfarland', 'admitted', 'in', 'an', 'email', 'to', 'colleague', 'during', 'the', '2016', 'presidential', 'transition', 'to', 'russia', 'throwing', 'the', 'election', 'to', 'trump', 'the', 'leaked', 'email', 'was', 'written', 'just', 'weeks', 'before', 'trump', 'inauguration', 'and', 'it', 'states', 'that', 'sanctions', 'would', 'make', 'it', 'difficult', 'to', 'ease', 'relations', 'with', 'russia', 'which', 'has', 'just', 'thrown', 'the', 'usa', 'election', 'to', 'him', 'the', 'new', 'york', 'times', 'reportsbut', 'emails', 'among', 'top', 'transition', 'officials', 'provided', 'or', 'described', 'to', 'the', 'new', 'york', 'times', 'suggest', 'that', 'mr', 'flynn', 'was', 'far', 'from', 'rogue', 'actor', 'in', 'fact', 'the', 'emails', 'coupled', 'with', 'interviews', 'and', 'court', 'documents', 'filed', 'on', 'friday', 'showed', 'that', 'mr', 'flynn', 'was', 'in', 'close', 'touch', 'with', 'other', 'senior', 'members', 'of', 'the', 'trump', 'transition', 'team', 'both', 'before', 'and', 'after', 'he', 'spoke', 'with', 'the', 'russian', 'ambassador', 'sergey', 'kislyak', 'about', 'american', 'sanctions', 'against', 'russiaa', 'white', 'house', 'lawyer', 'tried', 'to', 'explain', 'mcfarland', 'email', 'to', 'the', 'the', 'times', 'by', 'saying', 'that', 'she', 'was', 'referring', 'to', 'the', 'democrats', 'portrayal', 'of', 'the', 'election', 'that', 'doesn', 'make', 'any', 'sense', 'by', 'the', 'waymcfarland', 'wrote', 'the', 'email', 'to', 'thomas', 'bossert', 'who', 'currently', 'serves', 'as', 'trump', 'homeland', 'security', 'adviser', 'then', 'he', 'forwarded', 'it', 'to', 'future', 'national', 'security', 'advisor', 'michael', 'flynn', 'now', 'indicted', 'future', 'chief', 'of', 'staff', 'reince', 'priebus', 'future', 'senior', 'strategist', 'stephen', 'bannon', 'and', 'future', 'press', 'secretary', 'sean', 'spicer', 'the', 'daily', 'beast', 'reportswith', 'all', 'the', 'pearlclutching', 'we', 'witnessed', 'from', 'conservatives', 'about', 'hillary', 'clinton', 'emails', 'you', 'think', 'they', 'wouldn', 'be', 'sending', 'messages', 'about', 'russia', 'throwing', 'the', 'election', 'to', 'trumpthis', 'past', 'march', 'john', 'oliver', 'the', 'host', 'of', 'the', 'hbo', 'comedy', 'show', 'last', 'week', 'tonight', 'started', 'segment', 'called', 'stupid', 'watergate', 'which', 'he', 'described', 'as', 'scandal', 'with', 'all', 'the', 'potential', 'ramifications', 'of', 'watergate', 'but', 'where', 'everyone', 'involved', 'is', 'stupid', 'and', 'bad', 'at', 'everything', 'nailed', 'itphoto', 'by', 'chip', 'somodevilla']\n"
     ]
    }
   ],
   "source": [
    "print(texts_split[42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ae2b366-e14c-409b-b06e-18a9b38a98c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean and median number of words in texts: 404.93019340052854 & 356.0\n"
     ]
    }
   ],
   "source": [
    "# one last preprocessing step is that I would like to cut the length of the texts to have a \"light\" model\n",
    "lens = [len(text) for text in texts_split]\n",
    "print(\"mean and median number of words in texts:\", np.mean(lens), '&', np.median(lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f2f899d-884c-4fe4-92af-304bd3832bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I push this number up to 400 and cut all the texts up to this number\n",
    "max_len = 400\n",
    "for i, text in enumerate(texts_split):\n",
    "    texts_split[i] = text[:max_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb75a6ad-0a8d-43a7-b9f2-aafa6694660f",
   "metadata": {},
   "source": [
    "#### Embedding layer and Tokenization\n",
    "You will need to download word2vec model ```GoogleNews-vectors-negative300-SLIM.bin.gz``` (approx. 300MB) from\n",
    "\n",
    "https://github.com/eyaler/word2vec-slim/blob/master/GoogleNews-vectors-negative300-SLIM.bin.gz\n",
    "\n",
    "and put it into the same folder the project is. \n",
    "\n",
    "This word2vec model was compiled from google news which suits quite well for this project.\n",
    "After loading the model I tokenize the texts according to the loaded word2vec model, i.e. I map the words from the corpus to the integers from lookup table of the model. As an output I have a 2D array of integers represting words in the news, each row is a seperate news text. I also cut long news and left pad short news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ff0ceca-7501-4716-8262-a6fe55d1ebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Need to run this cell once\n",
    "## unziping our word2vec model \n",
    "# ! gzip -d GoogleNews-vectors-negative300-SLIM.bin.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b5b178f-73fd-41cc-ab38-cf49fb77b42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299567 words in the vocabulary\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# loading the model\n",
    "embed_lookup = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300-SLIM.bin', \n",
    "                                                 binary=True)\n",
    "print(len(embed_lookup), 'words in the vocabulary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "771e7e6e-a421-4f8c-a5a6-a65aae6169b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of embedding:  300\n",
      "Index of ' news ' in the lookup table: 283\n"
     ]
    }
   ],
   "source": [
    "word = 'news'\n",
    "print(\"Length of embedding: \", len(embed_lookup[word]))  # dimension of the vector space of words\n",
    "# embed_lookup.index_to_key[:11]\n",
    "print(\"Index of '\", word, \"' in the lookup table:\", embed_lookup.key_to_index[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eefa96b1-6568-4dda-9eee-79495829ba81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization: For each news text we represent words as their index in the lookup table\n",
    "# unknown words are represnted as 0s, i.e. spaces\n",
    "tokenized_news = []\n",
    "for text in texts_split:\n",
    "    ints = []\n",
    "    for word in text:\n",
    "        try:\n",
    "            idx = embed_lookup.key_to_index[word]\n",
    "        except:\n",
    "            idx = 0\n",
    "        ints.append(idx)\n",
    "    tokenized_news.append(ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "015d00ed-8651-43ab-a8ae-670e081e3681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An example of a tokenized text: \n",
      " [177069, 23049, 378, 2326, 387, 348, 4042, 78551, 0, 234, 24411, 283, 5376, 0, 1790, 0, 24, 2165, 0, 7126, 128, 9, 0, 1874, 3226, 0, 127297, 3215, 9, 600, 0, 23049, 9, 8176, 2165, 8, 1465, 71, 410, 93, 23049, 9432, 0, 13, 713, 2, 3656, 42, 103, 13, 777, 0, 3268, 2090, 6, 127297, 43, 22, 71, 3381, 9, 73282, 600, 0, 88, 9, 60, 65033, 337, 0, 0, 341, 200, 3226, 232, 836, 26, 1280, 0, 9, 60, 65033, 337, 2731, 2, 64499, 0, 8, 330, 15, 14090, 2595, 0, 562, 9, 0, 6749, 6, 3529, 0, 321, 1578, 969, 4, 61858, 753, 2, 64499, 0, 8, 0, 374, 2369, 6, 61, 537, 264, 0, 9, 23049, 3226, 96, 172, 93, 0, 50, 20, 1538, 6, 9, 103824, 4994, 0, 0, 41, 46734, 3656, 97, 0, 1151, 513, 1801, 907, 0, 2873, 0, 2165, 0, 9, 9, 337, 16, 451, 2, 69, 8, 3653, 0, 9, 27631, 15090, 0, 9, 600, 2, 68710, 103, 95, 1131, 16, 9, 0, 1053, 9, 2165, 0, 121330, 0, 28, 664, 2639, 12, 23049, 9475, 348, 4042, 138, 20, 13048, 13, 0, 329, 387, 348, 6319, 88689, 0, 92, 6348, 329, 683, 0, 524, 0, 0, 329, 537, 7289, 142378, 0, 0, 329, 1221, 2114, 122635, 0, 9, 1306, 15434, 0, 47, 9, 0, 34, 5300, 15, 6338, 41, 154550, 118625, 0, 38, 144, 29, 98461, 14, 2320, 3363, 41, 127297, 3215, 9, 600, 0, 0, 246, 5387, 52144, 205488, 9, 1073, 0, 9, 211192, 3799, 245, 59, 110, 1606, 417, 3003, 250, 6536, 252880, 43, 20, 1280, 12, 3982, 6, 47, 9, 617, 15663, 0, 252880, 30, 111, 858, 637, 3, 6536, 0, 675, 10, 806, 13018, 0, 16, 4355, 0]\n"
     ]
    }
   ],
   "source": [
    "print('An example of a tokenized text: \\n', tokenized_news[42])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aad5dd-6099-4391-9d3e-d897446f9ec2",
   "metadata": {},
   "source": [
    "#### Padding\n",
    "Since I have already cut my texts up to ```max_len``` I will need to left pad with 0s all the texts that are shorter than this number. This will bring all the texts to the same length. I will end up with a 2D array with as many rows as there are news texts and as many columns as ```max_len``` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e7284fe-8155-45b5-8235-ab73064ce695",
   "metadata": {},
   "outputs": [],
   "source": [
    "pttexts = np.zeros((len(tokenized_news), max_len), dtype=int)\n",
    "for i, tok_text in enumerate(tokenized_news):\n",
    "    pttexts[i, -len(tok_text):] = tok_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99c97c4c-81dc-4f39-8d49-632e48a411aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded and tokenized first 11 texts up to first 10 words \n",
      " [[177069  23049     71  93409   2157     47  69404   1013     60     32]\n",
      " [     0      0      0      0      0      0      0      0      0      0]\n",
      " [     4  61858     13      8   1744      2    234 178446   4053  81995]\n",
      " [     4  68834    107 177069  23049    317      2     20     42     14]\n",
      " [  7705 205961    219     23    647  68834    107   1197      0  24121]\n",
      " [     0      0      0      0      0      0      0      0      0      0]\n",
      " [     0      0      0      0      0      0      0      0      0      0]\n",
      " [     0      0      0      0      0      0      0      0      0      0]\n",
      " [   124     63     19    965      9   6764   1732      9    562      2]\n",
      " [     0      0      0      0      0      0      0      0      0      0]\n",
      " [     0      0      0      0      0      0      0      0      0      0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"padded and tokenized first 11 texts up to first 10 words \\n\", pttexts[:11, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b0a29b4-da70-46e9-8411-00dc076d6c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42761 42761\n"
     ]
    }
   ],
   "source": [
    "# converting labels into 0s and 1s: 0 for true and 1 for fake\n",
    "# checking that we haven't lost any news\n",
    "labels = np.array([0 if label == 'true' else 1 for label in df['label']])\n",
    "print(len(labels), len(pttexts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547326c2-a5a4-4978-b9b3-d5e72b49a7a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### CNN model\n",
    "Now I take the preprocessed data, split it into training, test and validation sets. Then I take the CNN model, load the data and train. \n",
    "\n",
    "From here on I will follow the algorithm on which this CNN model is based sometimes adding my own comments. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "515600af-3ff0-4d62-9808-87de9416e587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tDatasets Shapes:\n",
      "Train set: \t\t(34208, 400) \n",
      "Validation set: \t(4276, 400) \n",
      "Test set: \t\t(4277, 400)\n"
     ]
    }
   ],
   "source": [
    "split_frac = 0.8\n",
    "\n",
    "# split data into training, validation, and test data (tokenized+padded texts and labels, x and y)\n",
    "\n",
    "split_idx = int(len(pttexts)*split_frac)\n",
    "train_x, remaining_x = pttexts[:split_idx], pttexts[split_idx:]\n",
    "train_y, remaining_y = labels[:split_idx], labels[split_idx:]\n",
    "\n",
    "test_idx = int(len(remaining_x)*0.5)\n",
    "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
    "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
    "\n",
    "## print out the shapes of your resultant feature data\n",
    "print(\"\\t\\t\\tDatasets Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
    "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947ca149-3443-4f3e-b521-dc37d5424c91",
   "metadata": {},
   "source": [
    "#### DataLoaders and Batching\n",
    "Batching is a common technique that is used to split data into smaller... well, batches, so that the machine is not overloaded with all data at once and the memory is not littered with errors. Basically speaking makes the training faster.\n",
    "We need to transfrom data into a fromat for pytorch, namely [TensorDataset](<https://pytorch.org/docs/stable/data.html#>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d26f9e0-e146-45eb-b373-2bf28e29522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# create Tensor datasets\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
    "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 128\n",
    "\n",
    "# shuffling and batching data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e031f58a-88bb-4bd9-a3e4-c77e1901e9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, training on CPU.\n"
     ]
    }
   ],
   "source": [
    "# First checking if GPU is available\n",
    "train_on_gpu=torch.cuda.is_available()\n",
    "\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU.')\n",
    "else:\n",
    "    print('No GPU available, training on CPU.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2febb24-4a60-4d52-8aa4-e9db4667f58b",
   "metadata": {},
   "source": [
    "Below is a class for our CNN model. Which is taken from Cezanne Camacho [2] who also has a very nice write up on the text applied CNN (https://cezannec.github.io/CNN_Text_Classification/ also I borrowed the gifs from her), which I highly recommened to read if you want to get more details.\n",
    "\n",
    "#### 1.Embedding\n",
    "The first part of the model is embedding layer, where the pretrained word2vec model is loaded.\n",
    "\n",
    "#### 2. Then convolutional layers come\n",
    "\n",
    "I would like to look for semantic patterns. Usually, a single word by itself doesn't give much perspective on the meaning of the text, but rather the word and its context let us understand the text. Same rule will be applied to this network. We will be looking at n-grams, n consequitive words in the text, to capture local features. For example in a text:\n",
    "\n",
    "> *I drink coffee every morning*\n",
    "\n",
    "there are three 3-grams:\n",
    "\n",
    "*I drink coffee*, *drink coffee every*, *coffee every morning*\n",
    "\n",
    "I am going to use . Having more than 5-grams doesn't make much sense, as the locality of the features is lost.\n",
    "\n",
    "In order to look for semantic patterns, convolutional kernels are used. They are represented by matrices filled with numbers, weights. In the case of text, these kernels will be applied to n-grams of the text, hence their dimensions will be 3x, 4x, 5x300, where 300 is the length of embedding.\n",
    "Then these matrices are going to slide over our news texts (padded and tokenized) looking for semantic patterns. At each step of this sliding process an elementwise matrix multiplication happens followed by summation of all elements of the resulting matrix. The sliding operation is called convolution and gives the name to Convolutional Neural Network.\n",
    "\n",
    "![](https://cezannec.github.io/assets/cnn_text/conv_kernel_operation.gif)\n",
    "\n",
    "The result of all multiplications gives a feature vector corresponding to the applied kernel. The network will contain many kernels and as the model trains the weights in the kernels will be updated. The result of applying many kernels is put into a stacked feature vector. This finilizes the convolutional layer of the model.\n",
    "\n",
    "![](https://cezannec.github.io/assets/cnn_text/conv_1D_time.gif)\n",
    "\n",
    "There will be 3 convolutional layers corresponding to 3-, 4-, 5-grams.\n",
    "\n",
    "#### 3. ReLu and Maxpooling\n",
    "This procedure is aimed at extraction of the most important features. Basically it tells us which feature gives the max value in the concolution by extracting maximum value from the feature vector. ReLu function is a Heaviside function times the input, it removes negative values (nonimportant features) from the feature vector.\n",
    "\n",
    "To be continued...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80e76e83-83b1-474b-8641-139b99a695f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SentimentCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    The embedding layer + CNN model that will be used to perform sentiment analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embed_model, vocab_size, output_size, embedding_dim,\n",
    "                 num_filters=100, kernel_sizes=[3, 4, 5], freeze_embeddings=True, drop_prob=0.5):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers.\n",
    "        \"\"\"\n",
    "        super(SentimentCNN, self).__init__()\n",
    "\n",
    "        # set class vars\n",
    "        self.num_filters = num_filters\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        # 1. embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # set weights to pre-trained\n",
    "        self.embedding.weight = nn.Parameter(torch.from_numpy(embed_model.vectors)) # all vectors\n",
    "        # (optional) freeze embedding weights\n",
    "        if freeze_embeddings:\n",
    "            self.embedding.requires_grad = False\n",
    "        \n",
    "        # 2. convolutional layers\n",
    "        # even though it's Conv2d, effectively it's 1d thanks to carefully chosen dimensions.\n",
    "        self.convs_1d = nn.ModuleList([\n",
    "            nn.Conv2d(1, num_filters, (k, embedding_dim), padding=(k-2,0)) \n",
    "            for k in kernel_sizes])\n",
    "        \n",
    "        # 3. final, fully-connected layer for classification\n",
    "        self.fc = nn.Linear(len(kernel_sizes) * num_filters, output_size) \n",
    "        \n",
    "        # 4. dropout and sigmoid layers\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "    \n",
    "    def conv_and_pool(self, x, conv):\n",
    "        \"\"\"\n",
    "        Convolutional + max pooling layer\n",
    "        \"\"\"\n",
    "        # squeeze last dim to get size: (batch_size, num_filters, conv_seq_length)\n",
    "        # conv_seq_length will be ~ 200\n",
    "        x = F.relu(conv(x)).squeeze(3)\n",
    "        \n",
    "        # 1D pool over conv_seq_length\n",
    "        # squeeze to get size: (batch_size, num_filters)\n",
    "        x_max = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
    "        return x_max\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defines how a batch of inputs, x, passes through the model layers.\n",
    "        Returns a single, sigmoid-activated class score as output.\n",
    "        \"\"\"\n",
    "        # embedded vectors\n",
    "        embeds = self.embedding(x) # (batch_size, seq_length, embedding_dim)\n",
    "        # embeds.unsqueeze(1) creates a channel dimension that conv layers expect\n",
    "        embeds = embeds.unsqueeze(1)\n",
    "        \n",
    "        # get output of each conv-pool layer\n",
    "        conv_results = [self.conv_and_pool(embeds, conv) for conv in self.convs_1d]\n",
    "        \n",
    "        # concatenate results and add dropout\n",
    "        x = torch.cat(conv_results, 1)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # final logit\n",
    "        logit = self.fc(x) \n",
    "        \n",
    "        # sigmoid-activated --> a class score\n",
    "        return self.sig(logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4abb835-921d-4990-bac1-39ed3142ccb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentCNN(\n",
      "  (embedding): Embedding(299567, 300)\n",
      "  (convs_1d): ModuleList(\n",
      "    (0): Conv2d(1, 100, kernel_size=(3, 300), stride=(1, 1), padding=(1, 0))\n",
      "    (1): Conv2d(1, 100, kernel_size=(4, 300), stride=(1, 1), padding=(2, 0))\n",
      "    (2): Conv2d(1, 100, kernel_size=(5, 300), stride=(1, 1), padding=(3, 0))\n",
      "  )\n",
      "  (fc): Linear(in_features=300, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model w/ hyperparams\n",
    "\n",
    "vocab_size = len(embed_lookup)\n",
    "output_size = 1 # binary class (1 or 0)\n",
    "embedding_dim = len(embed_lookup[word]) # 300-dim vectors\n",
    "\n",
    "num_filters = 100\n",
    "kernel_sizes = [3, 4, 5]\n",
    "\n",
    "net = SentimentCNN(embed_lookup, vocab_size, output_size, embedding_dim,\n",
    "                   num_filters, kernel_sizes)\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ce92dc2-1c83-43db-8530-fff9be47acc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimization functions\n",
    "lr=0.001\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a637881b-2505-49c3-aad7-25dfa1dc8f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "def train(net, train_loader, epochs, print_every=100):\n",
    "\n",
    "    # move model to GPU, if available\n",
    "    if(train_on_gpu):\n",
    "        net.cuda()\n",
    "\n",
    "    counter = 0 # for printing\n",
    "    \n",
    "    # train for some number of epochs\n",
    "    net.train()\n",
    "    for e in range(epochs):\n",
    "\n",
    "        # batch loop\n",
    "        for inputs, labels in train_loader:\n",
    "            counter += 1\n",
    "\n",
    "            if(train_on_gpu):\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "            # zero accumulated gradients\n",
    "            net.zero_grad()\n",
    "\n",
    "            # get the output from the model\n",
    "            output = net(inputs)\n",
    "\n",
    "            # calculate the loss and perform backprop\n",
    "            loss = criterion(output.squeeze(), labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # loss stats\n",
    "            if counter % print_every == 0:\n",
    "                # Get validation loss\n",
    "                val_losses = []\n",
    "                net.eval()\n",
    "                for inputs, labels in valid_loader:\n",
    "\n",
    "                    if(train_on_gpu):\n",
    "                        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "                    output = net(inputs)\n",
    "                    val_loss = criterion(output.squeeze(), labels.float())\n",
    "\n",
    "                    val_losses.append(val_loss.item())\n",
    "\n",
    "                net.train()\n",
    "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                      \"Step: {}...\".format(counter),\n",
    "                      \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                      \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1aeb0b5c-2088-4873-8a21-5ca82f8725f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/4... Step: 100... Loss: 0.151909... Val Loss: 0.333556\n",
      "Epoch: 1/4... Step: 200... Loss: 0.066964... Val Loss: 0.284256\n",
      "Epoch: 2/4... Step: 300... Loss: 0.014194... Val Loss: 0.222401\n",
      "Epoch: 2/4... Step: 400... Loss: 0.013228... Val Loss: 0.144858\n",
      "Epoch: 2/4... Step: 500... Loss: 0.004235... Val Loss: 0.120377\n",
      "Epoch: 3/4... Step: 600... Loss: 0.009919... Val Loss: 0.186595\n",
      "Epoch: 3/4... Step: 700... Loss: 0.007861... Val Loss: 0.132899\n",
      "Epoch: 3/4... Step: 800... Loss: 0.011659... Val Loss: 0.131367\n",
      "Epoch: 4/4... Step: 900... Loss: 0.000598... Val Loss: 0.163213\n",
      "Epoch: 4/4... Step: 1000... Loss: 0.001169... Val Loss: 0.176086\n"
     ]
    }
   ],
   "source": [
    "# training params\n",
    "\n",
    "epochs = 4 # this is approx where I noticed the validation loss stop decreasing\n",
    "print_every = 100\n",
    "\n",
    "train(net, train_loader, epochs, print_every=print_every)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3151a1f7-d01a-49bb-a84e-4ba5a91fa2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.241\n",
      "Test accuracy: 0.933\n"
     ]
    }
   ],
   "source": [
    "# Get test data loss and accuracy\n",
    "\n",
    "test_losses = [] # track loss\n",
    "num_correct = 0\n",
    "\n",
    "\n",
    "net.eval()\n",
    "# iterate over test data\n",
    "for inputs, labels in test_loader:\n",
    "\n",
    "    if(train_on_gpu):\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "    \n",
    "    # get predicted outputs\n",
    "    output = net(inputs)\n",
    "    \n",
    "    # calculate loss\n",
    "    test_loss = criterion(output.squeeze(), labels.float())\n",
    "    test_losses.append(test_loss.item())\n",
    "    \n",
    "    # convert output probabilities to predicted class (0 or 1)\n",
    "    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
    "    \n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "\n",
    "\n",
    "# -- stats! -- ##\n",
    "# avg test loss\n",
    "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
    "\n",
    "# accuracy over all test data\n",
    "test_acc = num_correct/len(test_loader.dataset)\n",
    "print(\"Test accuracy: {:.3f}\".format(test_acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648dd98d-0c1f-4b41-bc15-34f320dc510d",
   "metadata": {},
   "source": [
    "### References\n",
    "1. https://www.datacamp.com/community/tutorials/scikit-learn-fake-news\n",
    "2. https://cezannec.github.io/CNN_Text_Classification/\n",
    "3. https://github.com/eyaler/word2vec-slim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a5cdfc-8bc8-40f3-b779-499710b6d16f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676ff286-7768-4264-9339-ea540aa76a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
