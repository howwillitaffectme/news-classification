{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1988764-6826-495f-b6be-ee321951154b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Text classification for fake news detection\n",
    "\n",
    "In this notebook I train and evaluate 3 different ML models from sklearn library, namely:\n",
    "- Passive Aggressive Classifier\n",
    "- Logistic Regression\n",
    "- Linear SVC\n",
    "All three models use TF-iDF vectorizer, a frequency based textvectorizer.\n",
    "The models will classify news based only on the text or title of the news.\n",
    "\n",
    "The investigation is structured in the following manner:\n",
    "1. Read and preprocess data.\n",
    "2. Split data into training and test sets, vectorize it for models input.\n",
    "3. Training and evaluation of models.\n",
    "4. Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaaf646-485a-474f-bfdc-9749cb598d1a",
   "metadata": {},
   "source": [
    "Download dataset: https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset and extract into the same folder this notebook is in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d1f0b1f-53be-4ee9-b273-8dea60e44cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "# text processing, term frequency based\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "# models\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier, LogisticRegression\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be85617a-25e5-430a-a808-34d03d530a41",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "The input data is not 'clean'. Apperently many \"true\" news contain a source in the begining of their \"text\" field, and many \"fake\" news contain related pic info in the end of their \"text\" field, this can cause bias for a model, so we can cut them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59522b62-1bb8-41ae-a841-5fdb23237ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutsource(s):\n",
    "    ''' a function to cut out news source in \"true\" texts\n",
    "        luckily they are separated by '-' (dash sign)\n",
    "    '''\n",
    "    if '- ' in s:\n",
    "        s1 = s.split('- ')[0]\n",
    "        s = s[len(s1)+2:]\n",
    "        \n",
    "    return s\n",
    "\n",
    "def cutgetty(s):\n",
    "    ''' a function to cut out 'getty images' in \"fake\" texts\n",
    "    '''\n",
    "    s = re.sub('Getty Images', '', s)\n",
    "    \n",
    "    return s\n",
    "\n",
    "def cutfactbox(s):\n",
    "    ''' a function to cut out 'factbox' in \"true\" titles\n",
    "    '''\n",
    "    s = re.sub('factbox', '', s, flags=re.IGNORECASE)\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55981c0b-97fe-42e5-84f1-0bad6c12ef3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = pd.read_csv('Fake.csv')\n",
    "true = pd.read_csv('True.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03180ebf-19cb-49c9-9686-0ba7f7ac0f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaked Email Proves Trump Officials Aware Russia Had ‘Thrown The USA Election’ To Trump\n",
      "Donald Trump s current deputy national security adviser K.T. McFarland, a former Fox News personality, K. T. McFarland admitted in an email to a colleague during the 2016 presidential transition to Russia throwing the election to Trump. The leaked email was written just weeks before Trump s inauguration and it states that sanctions would make it difficult to ease relations with Russia,  which has just thrown the U.S.A. election to him. The New York Times reports:But emails among top transition officials, provided or described to The New York Times, suggest that Mr. Flynn was far from a rogue actor. In fact, the emails, coupled with interviews and court documents filed on Friday, showed that Mr. Flynn was in close touch with other senior members of the Trump transition team both before and after he spoke with the Russian ambassador, Sergey I. Kislyak, about American sanctions against Russia.A White House lawyer tried to explain McFarland s email to the The Times by saying that she was referring to the Democrats  portrayal of the election. That doesn t make any sense, by the way.McFarland wrote the email to Thomas P. Bossert, who currently serves as Trump s homeland security adviser, then he forwarded it to future National Security Advisor Michael Flynn (now indicted), future Chief of Staff Reince Priebus, future senior strategist Stephen Bannon, and future press secretary Sean Spicer, the Daily Beast reports.With all the pearl-clutching we witnessed from conservatives about Hillary Clinton s emails, you d think they wouldn t be sending messages about Russia throwing the election to Trump.This past March, John Oliver, the host of the HBO comedy show Last Week Tonight started a segment called  Stupid Watergate,  which he described as  a scandal with all the potential ramifications of Watergate, but where everyone involved is stupid and bad at everything. Nailed it!Photo by Chip Somodevilla/.\n",
      "fake\n"
     ]
    }
   ],
   "source": [
    "true['text'] = true['text'].apply(cutsource)\n",
    "fake['text'] = fake['text'].apply(cutgetty)\n",
    "true['title'] = true['title'].apply(cutfactbox)\n",
    "# combine data into 1 dataframe, discarding 'date' and 'subject' fields, \n",
    "# removing rows with empty text or title.\n",
    "cols = ['title', 'text']\n",
    "df = pd.concat([fake[cols], true[cols]], ignore_index=True)\n",
    "df['text'] = df['text'].str.strip()\n",
    "df['title'] = df['title'].str.strip()\n",
    "label = len(fake)*['fake'] + len(true)*['true']\n",
    "df['label'] = label\n",
    "# drop news shorter than a tweet\n",
    "df = df[df['text'].str.len() > 280]\n",
    "df = df.replace('', np.nan)\n",
    "df.dropna(inplace=True)\n",
    "df['label'].value_counts()\n",
    "example = df.iloc[42]\n",
    "print(example['title'] + '\\n' + example['text'] + '\\n' + example['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412d4020-76f5-4e0f-9a8e-889bf330bbd0",
   "metadata": {},
   "source": [
    "### Machine learning time. \n",
    "Training will consider 2 cases: title only and text only classification.\n",
    "\n",
    "For word processing I use TF-iDF, a frequency based metric, which checks the occurence of a term against a given text and the whole corpus.\n",
    "\n",
    "Here I construct a function for evaluation of different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cf59cc9-7063-4a1e-b9ce-c6e511fad000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(df_col):\n",
    "    '''split data into train and test, turn into vectors.\n",
    "    '''\n",
    "    x_train,x_test,y_train,y_test=train_test_split(df[df_col], df['label'], test_size=0.2, random_state=42, shuffle=True)\n",
    "    # Learn vocabulary and idf, return document-term matrix.\n",
    "    tfidf_vectorizer=TfidfVectorizer(stop_words='english', max_df=0.75)\n",
    "    vec_train=tfidf_vectorizer.fit_transform(x_train.values.astype('U')) \n",
    "    # Transform documents to document-term matrix.\n",
    "    vec_test=tfidf_vectorizer.transform(x_test.values.astype('U'))\n",
    "    \n",
    "    return (tfidf_vectorizer, vec_train, vec_test, y_train, y_test)\n",
    "    \n",
    "def model_eval(input_data, model):\n",
    "    '''function to report f1 scores for a model\n",
    "        based on classification based on df_col (text or title)\n",
    "        tdidf_vectorizer\n",
    "        https://github.com/satssehgal/FakeNewsDetector\n",
    "    '''\n",
    "    tfidf_vectorizer, vec_train, vec_test, y_train, y_test = input_data\n",
    "    model.fit(vec_train,y_train)\n",
    "    y_pred=model.predict(vec_test)\n",
    "    f1 = f1_score(y_test, y_pred, pos_label='fake')\n",
    "    # let's see what are the top terms for fake and true news (largest vectors)\n",
    "    # https://www.datacamp.com/community/tutorials/scikit-learn-fake-news\n",
    "    terms = tfidf_vectorizer.get_feature_names_out()\n",
    "    keywords = sorted(zip(model.coef_[0], terms), reverse=True)\n",
    "    keywords_true = np.array(keywords[:20])\n",
    "    keywords_fake = np.flip(np.array(keywords[-20:]), axis=0)\n",
    "    true_out = keywords_true[:, 1]\n",
    "    fake_out = keywords_fake[:, 1]\n",
    "\n",
    "    print('F1 score', f1)\n",
    "    print('\\t True keywords: \\n', true_out)\n",
    "    print('\\t Fake keywords: \\n', fake_out)\n",
    "    \n",
    "    return (f1, true_out, fake_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80fe08ea-be91-451e-b3ef-979f3a72c392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*--------- PassiveAggressiveClassifier ---------*\n",
      "## Title based classification ##\n",
      "F1 score 0.9396904870277653\n",
      "\t True keywords: \n",
      " ['says' 'exclusive' 'faults' 'spokesman' 'fame' 'rohingya' 'german'\n",
      " 'kremlin' 'hindu' 'kabul' 'talks' 'pakistan' 'blitz' 'vulgar' 'myanmar'\n",
      " 'employs' 'fights' 'collar' 'north' 'inspiration']\n",
      "\t Fake keywords: \n",
      " ['video' 'breaking' 'racist' 'gop' 'just' 'hillary' 'joe' 'illegals'\n",
      " 'james' 'anonymous' 'ck' 'actually' 'watch' 'gitmo' 'ammo' 'globalist'\n",
      " 'mails' 'dems' 'dog' 'shocking']\n",
      "## Text based classification ##\n",
      "F1 score 0.9878884826325411\n",
      "\t True keywords: \n",
      " ['thursday' 'tuesday' 'wednesday' 'nov' 'friday' 'republican' 'reuters'\n",
      " 'monday' 'donald' 'spokeswoman' 'rival' 'representatives' 'comment'\n",
      " 'spokesman' 'barack' 'statement' 'referring' 'reporters' 'saying'\n",
      " 'television']\n",
      "\t Fake keywords: \n",
      " ['featured' 'image' 'read' 'gop' 'com' 'sen' 'just' 'breitbart' 'rep'\n",
      " 'pic' 'watch' 'mr' 'wfb' 'https' 'daily' 'hillary' 'wire' '21st' 'mail'\n",
      " 'reportedly']\n",
      "*--------- LogisticRegression ---------*\n",
      "## Title based classification ##\n",
      "F1 score 0.9417195614541258\n",
      "\t True keywords: \n",
      " ['says' 'china' 'house' 'talks' 'myanmar' 'senate' 'urges' 'german'\n",
      " 'south' 'turkey' 'pm' 'britain' 'lawmakers' 'brexit' 'tax' 'eu' 'ex'\n",
      " 'probe' 'exclusive' 'opposition']\n",
      "\t Fake keywords: \n",
      " ['video' 'hillary' 'watch' 'breaking' 'just' 'gop' 'america' 'tweets'\n",
      " 'muslim' 'racist' 'donald' 'details' 'bernie' 'obama' 'boiler' 'isis'\n",
      " 'wow' 'black' 'images' 'liberal']\n",
      "## Text based classification ##\n",
      "F1 score 0.9764989109251404\n",
      "\t True keywords: \n",
      " ['wednesday' 'reuters' 'thursday' 'tuesday' 'republican' 'friday' 'monday'\n",
      " 'spokesman' 'statement' 'nov' 'presidential' 'reporters' 'minister'\n",
      " 'comment' 'democratic' 'told' 'representatives' 'spokeswoman' 'sunday'\n",
      " 'edt']\n",
      "\t Fake keywords: \n",
      " ['image' 'featured' 'just' 'read' 'gop' 'com' 'hillary' 'watch' 'america'\n",
      " 'pic' 'mr' 'like' 'https' 'sen' 'video' 'daily' 'rep' 'american' 'fact'\n",
      " 'wire']\n",
      "*--------- LinearSVC ---------*\n",
      "## Title based classification ##\n",
      "F1 score 0.9514119126557676\n",
      "\t True keywords: \n",
      " ['says' 'britain' 'german' 'urges' 'myanmar' 'rohingya' 'exclusive'\n",
      " 'spokesman' 'turkey' 'talks' 'singapore' 'pakistan' 'kremlin' 'house'\n",
      " 'faults' 'colombia' 'indonesian' 'spain' 'negotiations' 'egypt']\n",
      "\t Fake keywords: \n",
      " ['video' 'breaking' 'gop' 'just' 'hillary' 'watch' 'racist' 'bernie'\n",
      " 'boiler' 'illegals' 'isis' 'ck' 'actually' 'doj' 'dem' 'shocking' 'james'\n",
      " 'sharia' 'joe' 'anonymous']\n",
      "## Text based classification ##\n",
      "F1 score 0.9880013712718547\n",
      "\t True keywords: \n",
      " ['thursday' 'wednesday' 'tuesday' 'reuters' 'nov' 'friday' 'monday'\n",
      " 'republican' 'statement' 'spokesman' 'comment' 'spokeswoman' 'reporters'\n",
      " 'representatives' 'barack' 'donald' 'rival' 'presidential' 'referring'\n",
      " 'sunday']\n",
      "\t Fake keywords: \n",
      " ['featured' 'image' 'read' 'gop' 'just' 'com' 'sen' 'watch' 'pic'\n",
      " 'breitbart' 'rep' 'mr' 'daily' 'hillary' 'wfb' 'https' 'wire'\n",
      " 'reportedly' 'mail' '21st']\n"
     ]
    }
   ],
   "source": [
    "# split data into training and test sets, vectorize.\n",
    "title_data = data_split('title')\n",
    "text_data = data_split('text')\n",
    "\n",
    "# setting models and computing scores\n",
    "pac = PassiveAggressiveClassifier()\n",
    "lr = LogisticRegression()\n",
    "lsvc = LinearSVC()\n",
    "table = []\n",
    "for model in (pac, lr, lsvc):\n",
    "    print('*--------- '+type(model).__name__+' ---------*')\n",
    "    print('## Title based classification ##')\n",
    "    f1, true_m, fake_m = model_eval(title_data, model)\n",
    "    print('## Text based classification ##') \n",
    "    f1txt, true_mtxt, fake_mtxt = model_eval(text_data, model)\n",
    "    table.append([f1, true_m[:5], fake_m[:5], f1txt, true_mtxt[:5], fake_mtxt[:5]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42f71193-986d-440e-8ab8-8d22763828f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 score (title)</th>\n",
       "      <th>Top true (title)</th>\n",
       "      <th>Top fake (title)</th>\n",
       "      <th>F1 score (text)</th>\n",
       "      <th>Top true (text)</th>\n",
       "      <th>Top fake (text)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PAC</th>\n",
       "      <td>0.939690</td>\n",
       "      <td>[says, exclusive, faults, spokesman, fame]</td>\n",
       "      <td>[video, breaking, racist, gop, just]</td>\n",
       "      <td>0.987888</td>\n",
       "      <td>[thursday, tuesday, wednesday, nov, friday]</td>\n",
       "      <td>[featured, image, read, gop, com]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>0.941720</td>\n",
       "      <td>[says, china, house, talks, myanmar]</td>\n",
       "      <td>[video, hillary, watch, breaking, just]</td>\n",
       "      <td>0.976499</td>\n",
       "      <td>[wednesday, reuters, thursday, tuesday, republ...</td>\n",
       "      <td>[image, featured, just, read, gop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinSVC</th>\n",
       "      <td>0.951412</td>\n",
       "      <td>[says, britain, german, urges, myanmar]</td>\n",
       "      <td>[video, breaking, gop, just, hillary]</td>\n",
       "      <td>0.988001</td>\n",
       "      <td>[thursday, wednesday, tuesday, reuters, nov]</td>\n",
       "      <td>[featured, image, read, gop, just]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        F1 score (title)                            Top true (title)  \\\n",
       "PAC             0.939690  [says, exclusive, faults, spokesman, fame]   \n",
       "LogReg          0.941720        [says, china, house, talks, myanmar]   \n",
       "LinSVC          0.951412     [says, britain, german, urges, myanmar]   \n",
       "\n",
       "                               Top fake (title)  F1 score (text)  \\\n",
       "PAC        [video, breaking, racist, gop, just]         0.987888   \n",
       "LogReg  [video, hillary, watch, breaking, just]         0.976499   \n",
       "LinSVC    [video, breaking, gop, just, hillary]         0.988001   \n",
       "\n",
       "                                          Top true (text)  \\\n",
       "PAC           [thursday, tuesday, wednesday, nov, friday]   \n",
       "LogReg  [wednesday, reuters, thursday, tuesday, republ...   \n",
       "LinSVC       [thursday, wednesday, tuesday, reuters, nov]   \n",
       "\n",
       "                           Top fake (text)  \n",
       "PAC      [featured, image, read, gop, com]  \n",
       "LogReg  [image, featured, just, read, gop]  \n",
       "LinSVC  [featured, image, read, gop, just]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_ev = pd.DataFrame(table, index=['PAC', 'LogReg', 'LinSVC'], \n",
    "                         columns=['F1 score (title)', 'Top true (title)', 'Top fake (title)', \n",
    "                                 'F1 score (text)', 'Top true (text)', 'Top fake (text)'])\n",
    "models_ev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e862df6-36ea-4010-9e4b-cf7447276feb",
   "metadata": {},
   "source": [
    "NOTE: because of shuffle of input data the keywords might differ from run to run (e.g. starting a new kernel), I think the seed for random_state in train_test_split() is not uniquely determined for a given number.\n",
    "\n",
    "### Summary\n",
    "From the textbased classification we can conclude that the models identified true news as the ones that refer to to a person or other news, like 'said', 'showed', 'citing', 'comment' as well as containing a date (day).\n",
    "On the other hand, fake news seem to refer to images a lot (presumably in the news article) or links on the internet (e.g. pic.twitter.com/*). Also in contrast true news refer to particular days, while fake news refer to rather time adverbs, like 'just', 'daily', 'reportedly'.\n",
    "Alternatively fake news refer to rather screenshots than text citations.\n",
    "\n",
    "It is also plausible that fake news appeal to visual comprehension of information in contrast to true news appealing to verbal/idea based information. \n",
    "\n",
    "The title based classification shows that keywords like \"shocking\", \"breaking\", \"racist\" were identified for fake news. Fake news are similar to a virus, they are aimed at getting as many clicks as possible in short amount of time, indeed the  keywords for fake news look like clickbaiting words. While true news seem to have more neutral and passive keywords. \n",
    "\n",
    "Within this investigation all models show similar high F1 scores, with PAC and LogReg being slightly better than LogReg most of the times. At the same time textbased modelling shows higher scores than titlebased, which is reasinable, the more information is available, the more precise one can be (to some extent).\n",
    "\n",
    "We can conclude that all the models showed reasonable results which we can also interpret in a clear understandable manner.\n",
    "\n",
    "PAC was my first choice since I didn't really know what to pick, then I took LogisiticRegression for it being the simplest and easiest to understand, and  SVC as google said is one of the best for text classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648dd98d-0c1f-4b41-bc15-34f320dc510d",
   "metadata": {},
   "source": [
    "### References\n",
    "1. https://www.datacamp.com/community/tutorials/scikit-learn-fake-news\n",
    "2. https://cezannec.github.io/CNN_Text_Classification/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
